{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f84f0487",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning & Deployment Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9333c6",
   "metadata": {},
   "source": [
    "## What You'll Learn\n",
    "\n",
    "By the end of this tutorial, you'll know how to:\n",
    "\n",
    "    üîç Run intelligent hyperparameter optimization with Hyperopt and MLflow tracking\n",
    "    üìä Compare experiment results using MLflow's powerful visualization tools\n",
    "    üèÜ Identify and register your best model for production use\n",
    "    üöÄ Deploy models to REST APIs for real-time inference\n",
    "    üì¶ Build production containers ready for cloud deployment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22452006",
   "metadata": {},
   "source": [
    "## Prepare Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c0a810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-17 16:05:40.906348: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-17 16:05:40.910604: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-17 16:05:40.921199: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752764740.939706 1910577 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752764740.944955 1910577 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752764740.960018 1910577 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752764740.960044 1910577 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752764740.960047 1910577 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752764740.960050 1910577 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-17 16:05:40.964552: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "# Load the wine quality dataset\n",
    "data = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\",\n",
    "    sep=\";\",\n",
    ")\n",
    "\n",
    "# Create train/validation/test splits\n",
    "train, test = train_test_split(data, test_size=0.25, random_state=42)\n",
    "train_x = train.drop([\"quality\"], axis=1).values\n",
    "train_y = train[[\"quality\"]].values.ravel()\n",
    "test_x = test.drop([\"quality\"], axis=1).values\n",
    "test_y = test[[\"quality\"]].values.ravel()\n",
    "\n",
    "# Further split training data for validation\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(\n",
    "    train_x, train_y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create model signature for deployment\n",
    "signature = infer_signature(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8551072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train_model(learning_rate, momentum, epochs=10):\n",
    "    \"\"\"\n",
    "    Create and train a neural network with specified hyperparameters.\n",
    "\n",
    "    Returns:\n",
    "        dict: Training results including model and metrics\n",
    "    \"\"\"\n",
    "    # Normalize input features for better training stability\n",
    "    mean = np.mean(train_x, axis=0)\n",
    "    var = np.var(train_x, axis=0)\n",
    "\n",
    "    # Define model architecture\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input([train_x.shape[1]]),\n",
    "            keras.layers.Normalization(mean=mean, variance=var),\n",
    "            keras.layers.Dense(64, activation=\"relu\"),\n",
    "            keras.layers.Dropout(0.2),  # Add regularization\n",
    "            keras.layers.Dense(32, activation=\"relu\"),\n",
    "            keras.layers.Dense(1),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Compile with specified hyperparameters\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum),\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[keras.metrics.RootMeanSquaredError()],\n",
    "    )\n",
    "\n",
    "    # Train with early stopping for efficiency\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        patience=3, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_x,\n",
    "        train_y,\n",
    "        validation_data=(valid_x, valid_y),\n",
    "        epochs=epochs,\n",
    "        batch_size=64,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0,  # Reduce output for cleaner logs\n",
    "    )\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    val_loss, val_rmse = model.evaluate(valid_x, valid_y, verbose=0)\n",
    "\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"val_rmse\": val_rmse,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"history\": history,\n",
    "        \"epochs_trained\": len(history.history[\"loss\"]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d470a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space defined:\n",
      "- Learning rate: 1e-5 to 1e-1 (log-uniform)\n",
      "- Momentum: 0.0 to 0.9 (uniform)\n"
     ]
    }
   ],
   "source": [
    "def objective(params):\n",
    "    \"\"\"\n",
    "    Objective function for hyperparameter optimization.\n",
    "    This function will be called by Hyperopt for each trial.\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(nested=True):\n",
    "        # Log hyperparameters being tested\n",
    "        mlflow.log_params(\n",
    "            {\n",
    "                \"learning_rate\": params[\"learning_rate\"],\n",
    "                \"momentum\": params[\"momentum\"],\n",
    "                \"optimizer\": \"SGD\",\n",
    "                \"architecture\": \"64-32-1\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Train model with current hyperparameters\n",
    "        result = create_and_train_model(\n",
    "            learning_rate=params[\"learning_rate\"],\n",
    "            momentum=params[\"momentum\"],\n",
    "            epochs=15,\n",
    "        )\n",
    "\n",
    "        # Log training results\n",
    "        mlflow.log_metrics(\n",
    "            {\n",
    "                \"val_rmse\": result[\"val_rmse\"],\n",
    "                \"val_loss\": result[\"val_loss\"],\n",
    "                \"epochs_trained\": result[\"epochs_trained\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Log the trained model\n",
    "        mlflow.tensorflow.log_model(result[\"model\"], name=\"model\", signature=signature)\n",
    "\n",
    "        # Log training curves as artifacts\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        plt.figure(figsize=(12, 4))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(result[\"history\"].history[\"loss\"], label=\"Training Loss\")\n",
    "        plt.plot(result[\"history\"].history[\"val_loss\"], label=\"Validation Loss\")\n",
    "        plt.title(\"Model Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(\n",
    "            result[\"history\"].history[\"root_mean_squared_error\"], label=\"Training RMSE\"\n",
    "        )\n",
    "        plt.plot(\n",
    "            result[\"history\"].history[\"val_root_mean_squared_error\"],\n",
    "            label=\"Validation RMSE\",\n",
    "        )\n",
    "        plt.title(\"Model RMSE\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"RMSE\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"training_curves.png\")\n",
    "        mlflow.log_artifact(\"training_curves.png\")\n",
    "        plt.close()\n",
    "\n",
    "        # Return loss for Hyperopt (it minimizes)\n",
    "        return {\"loss\": result[\"val_rmse\"], \"status\": STATUS_OK}\n",
    "\n",
    "\n",
    "# Define search space for hyperparameters\n",
    "search_space = {\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(1e-5), np.log(1e-1)),\n",
    "    \"momentum\": hp.uniform(\"momentum\", 0.0, 0.9),\n",
    "}\n",
    "\n",
    "print(\"Search space defined:\")\n",
    "print(\"- Learning rate: 1e-5 to 1e-1 (log-uniform)\")\n",
    "print(\"- Momentum: 0.0 to 0.9 (uniform)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a5a9df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/17 16:13:15 INFO mlflow.tracking.fluent: Experiment with name 'wine-quality-optimization' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter optimization experiment: wine-quality-optimization\n",
      "This will run 15 trials to find optimal hyperparameters...\n",
      "  0%|          | 0/15 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-17 16:13:15.257482: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [02:07<00:00,  8.50s/trial, best loss: 0.6856499910354614]\n"
     ]
    }
   ],
   "source": [
    "# Create or set experiment\n",
    "experiment_name = \"wine-quality-optimization\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"Starting hyperparameter optimization experiment: {experiment_name}\")\n",
    "print(\"This will run 15 trials to find optimal hyperparameters...\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"hyperparameter-sweep\"):\n",
    "    # Log experiment metadata\n",
    "    mlflow.log_params(\n",
    "        {\n",
    "            \"optimization_method\": \"Tree-structured Parzen Estimator (TPE)\",\n",
    "            \"max_evaluations\": 15,\n",
    "            \"objective_metric\": \"validation_rmse\",\n",
    "            \"dataset\": \"wine-quality\",\n",
    "            \"model_type\": \"neural_network\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Run optimization\n",
    "    trials = Trials()\n",
    "    best_params = fmin(\n",
    "        fn=objective,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=15,\n",
    "        trials=trials,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # Find and log best results\n",
    "    best_trial = min(trials.results, key=lambda x: x[\"loss\"])\n",
    "    best_rmse = best_trial[\"loss\"]\n",
    "\n",
    "    # Log optimization results\n",
    "    mlflow.log_params(\n",
    "        {\n",
    "            \"best_learning_rate\": best_params[\"learning_rate\"],\n",
    "            \"best_momentum\": best_params[\"momentum\"],\n",
    "        }\n",
    "    )\n",
    "    mlflow.log_metrics(\n",
    "        {\n",
    "            \"best_val_rmse\": best_rmse,\n",
    "            \"total_trials\": len(trials.trials),\n",
    "            \"optimization_completed\": 1,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d13709d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted wine quality: 5.80\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Prepare test data\n",
    "test_wine = {\n",
    "    \"dataframe_split\": {\n",
    "        \"columns\": [\n",
    "            \"fixed acidity\",\n",
    "            \"volatile acidity\",\n",
    "            \"citric acid\",\n",
    "            \"residual sugar\",\n",
    "            \"chlorides\",\n",
    "            \"free sulfur dioxide\",\n",
    "            \"total sulfur dioxide\",\n",
    "            \"density\",\n",
    "            \"pH\",\n",
    "            \"sulphates\",\n",
    "            \"alcohol\",\n",
    "        ],\n",
    "        \"data\": [[7.0, 0.27, 0.36, 20.7, 0.045, 45, 170, 1.001, 3.0, 0.45, 8.8]],\n",
    "    }\n",
    "}\n",
    "\n",
    "# Make prediction request\n",
    "response = requests.post(\n",
    "    \"http://localhost:5002/invocations\",\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    "    data=json.dumps(test_wine),\n",
    ")\n",
    "\n",
    "prediction = response.json()\n",
    "print(f\"Predicted wine quality: {prediction['predictions'][0][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3db64e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
